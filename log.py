#!/usr/bin/env python

"""
This module is used to read/save log files metadata for each experiment. These 
are .txt files automatically generated by LabVIEW at the start of each 
experiment.

"""

import os
import re
import shutil
import traceback

import numpy as np
import cPickle as pickle

from datetime import datetime
from pandas import read_table
from skimage.io import imread

import read

__author__ = "Charlie Wright"
__email__ = "charles.s.wright@gmail.com"

DATETIME_FORMAT = '%Y-%m-%dT%H:%M:%S.%f'


def read_log(input_dir):
    """
    Read the log.txt file, which contains entries in the format "Key: Value". 
    All values are imported as strings, but some are converted to other formats 
    for convenience, and some parameters may be added to this dictionary:
        Start Date: converted to datetime (read_log)
        Total Frames [Phase/Fluor]: added as int (main)
        Total Positions: converted to int (main)
        Total Time: converted to float, in seconds (main)
        Experiment Name: added as str (read_log)

    args:
        input_dir (path): raw data experiment directory

    """

    # Read the results into a dictionary
    results = {}
    with open(os.path.join(input_dir, 'log.txt')) as f:
        for line in f:
            k, v = [s.strip() for s in line.strip('\n').split(':', 1)]
            results[k] = v

    # Convert start date from string to date time
    results['Start Date'] = datetime.strptime(results['Start Date'],
                                              DATETIME_FORMAT)

    # Add the name of the experiment from the directory name
    results['Experiment Name'] = os.path.basename(input_dir)

    return results

def read_img(input_dir):
    """
    Read image metadata. Search for both phase-contrast and fluorescence files.

    args:
        input_dir (path): raw data experiment directory

    """
    results = {k : {'include' : False, 'shape' : (0, 0), 'dtype' : None}
               for k in ('phase', 'fluor')}

    # Only look in the directory of the first position
    p = read.listdirs(input_dir, read.PATTERN['posndir']).next()

    # Try to read metadata about phase and fluor files (need one image each)
    for k in ('phase', 'fluor'):
        pattern = read.PATTERN['%stif' % k]
        for v in read.listfiles(os.path.join(input_dir, p), pattern):
            if os.path.splitext(v)[1] == '.tif':
                phase_img = imread(os.path.join(input_dir, p, v))
                results[k]['include'] = True
                results[k]['shape'] = phase_img.shape
                results[k]['dtype'] = phase_img.dtype
                break
    return results


def read_posns(input_dir):
    """
    Read (x, y, z) location of each position.

    args:
        input_dir (path): raw data experiment directory

    """
    results = []
    with open(os.path.join(input_dir, 'pos.txt')) as f:
        for line in f:
            try:
                v = tuple([float(s) for s in line.split()[1:]])
                results.append(v)
            except:
                traceback.print_exc()
                continue
    return results


def read_time(input_dir, start_date, img_type='phase'):
    """
    Read times for specified image type, converting absolute to relative values. 
    If a valid log file dictionary is given, the start time is subtracted from 
    there; otherwise, the start time is set to the minimum value in the 
    imported times.

    args:
        input_dir (path): raw data experiment directory
        start_date (datetime): start date and time of the experiment

    kwargs:
        img_type (str): 'phase' or 'fluor'

    """

    # Read in the image timestamps
    time = []
    with open(os.path.join(input_dir, img_type + '.txt')) as f:
        for line in f:
            v = [datetime.strptime(s, DATETIME_FORMAT) for s in line.split()]
            time.append(v)

    # Pad time points that do not have full number of positions
    numPosns = len(time[0])
    for v in time:
        numTimes = len(v)
        if numTimes < numPosns:
            v.extend([v[-1]] * (numPosns - numTimes))

    # Transpose by position
    time = map(list, zip(*time))

    # Convert to seconds since experiment start
    time = [[(u - start_date).total_seconds() for u in v] for v in time]
    return np.asarray(time)


def read_pumps(input_dir, log_dict):
    """
    Read in metadata about pump start/stop times, flow rates and units; also 
    save the solution used in each pump into these results.

    args:
        input_dir (path): raw data experiment directory
        log_dict (dict): log file parameter-value pairs (from read_log), with 
            updated fields corresponding to "Start Date" (datetime) and "Total 
            Time" in seconds (float)

    """

    # Read in pump information
    imported = []
    for p in read.listfiles(input_dir, r'^pump[\d]+\.txt$'):
        df = read_table(os.path.join(input_dir, p), header=None,
                        names=('DateTime', 'Rate'), index_col='DateTime')
        ts = [datetime.strptime(v, DATETIME_FORMAT) for v in df.index.values]
        df.index = [(v - log_dict['Start Date']).total_seconds() for v in ts]

        df['Units'] = ''
        for k, v in df['Rate'].iteritems():
            m = re.match(r'([0-9\.]*)([A-z]*)', v)
            df['Rate'].ix[k] = float(m.group(1))
            df['Units'].ix[k] = m.group(2)
        imported.append(df)

    # Find the solutions in the pumps
    soln_dict = {}
    for k, v in log_dict.iteritems():
        m = re.match('Pump ([0-9]+) Solution', k)
        if m:
            soln_dict[int(m.group(1))] = v
    soln_keys = sorted(soln_dict.keys())

    # Reformat according to on vs. off
    results = []
    for i, df in enumerate(imported):
        d = {'Time' : [], 'Rate' : [], 'Units' : '', 'Solution' : []}
        d['Solution'] = soln_dict[soln_keys[i]]
        for j, t1 in enumerate(df.index):
            r = df['Rate'].ix[t1]
            u = df['Units'].ix[t1]
            if j+1 < len(df.index):
                t2 = df.index[j+1]
            else:
                t2 = log_dict['Total Time']
            d['Rate'].append(r)
            if not d['Units']:
                # Convert pump unit codes to legible values (in TeX format)
                v, t = u[:2], u[2:]
                if v == 'UL':
                    v = u'\u03bcL'
                elif v == 'ML':
                    v == u'mL'
                if t == 'M':
                    t = '/min'
                elif t == 'H':
                    t = '/hr'
                d['Units'] = v + t
            d['Time'].append([t1, t2])
        results.append(d)
    return results


def main(input_dir, output_dir, positions=None, write_mode=0):
    """
    Read metadata from all log files in the input data directory.

    args:
        input_dir (path): raw data experiment directory
        output_dir (path): path to save pickled results

    """
    expt = dict.fromkeys(('log', 'image', 'pumps', 'stage'))

    # First read the main log.txt file
    expt['log'] = read_log(input_dir)

    # Transfer the log.txt file and rename it to experiment.log
    shutil.copy(os.path.join(input_dir, 'log.txt'),
                os.path.join(output_dir, 'experiment.log'))

    # Read in any image metadata available
    expt['image'] = read_img(input_dir)

    # Read in the positions
    expt['stage'] = read_posns(input_dir)
    expt['log']['Total Positions'] = len(expt['stage'])

    # Attempt to read the phase.txt and fluor.txt time files
    total_time = 0
    for k in expt['image'].keys():
        if expt['image'][k]['include']:
            expt[k] = read_time(input_dir, expt['log']['Start Date'], k)
            total_time = max(total_time, expt[k].max())
            expt['log']['Total Frames %s' % k.capitalize()] = expt[k].shape[1]
    expt['log']['Total Time'] = total_time

    # Then read in the pump rates and on/off values
    expt['pumps'] = read_pumps(input_dir, expt['log'])

    # Iterate over all positions in the experiment
    if positions is None:
        positions = read.listdirs(input_dir, read.PATTERN['posndir'])
    for p in positions:
        i = int(re.match(read.PATTERN['posndir'], p).group(2))

        # Create a log dictionary specific to each position
        posn = {}
        for k, v in expt.iteritems():
            if k in ('log', 'image', 'pumps'):
                posn[k] = v
            elif k in ('phase', 'fluor', 'stage'):
                posn[k] = v[i]

        # Add information about the specific position
        posn['log']['Position Name'] = p
        posn['log']['Position Number'] = i

        # Save the results
        read.rmkdir(os.path.join(output_dir, p))
        output_file = os.path.join(output_dir, p, 'log.pickle')
        if not os.path.isfile(output_file) or write_mode == 1:
            pickle.dump(posn, open(output_file, 'wb'))
